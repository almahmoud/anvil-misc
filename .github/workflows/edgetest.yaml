name: Run Deployment and Tool Tests for 21.01 pre-release
on:
  schedule:
    - cron: "0 * * * *"
  workflow_dispatch: {}
jobs:
  deploy:
    env:
      GKE_ZONE: us-east1-b
      GKE_VERSION: "1.18"
      GXY_TMP: /tmp/gxy
      PREFIX: gxy-auto
    runs-on: ubuntu-latest
    outputs:
      prefix: ${{ steps.prefix.outputs.prefix }}
    steps:
      - name: Set prefix with date
        id: prefix
        run: echo "::set-output name=prefix::$(echo $PREFIX-$(date +'%m-%d-%H-%M-%S'))"
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@master
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          export_default_credentials: true
      - name: Create two GCP Disks
        run: gcloud compute disks create "${{steps.prefix.outputs.prefix}}-postgres-pd" --size 10Gi --zone "$GKE_ZONE" && gcloud compute disks create "${{steps.prefix.outputs.prefix}}-nfs-pd" --size 250Gi --zone "$GKE_ZONE"
      - name: Create GKE cluster
        run: gcloud container clusters create "${{steps.prefix.outputs.prefix}}" --cluster-version="$GKE_VERSION" --disk-size=100 --num-nodes=1 --machine-type=n1-highmem-8 --zone "$GKE_ZONE"
      - name: Install Kubectl
        run: curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl" && chmod +x ./kubectl && sudo mv ./kubectl /usr/local/bin/kubectl && kubectl version
      - name: Install Helm
        run: curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
      - name: Add Anvil repository
        run: helm repo add edge https://github.com/almahmoud/helm-charts/raw/gkm-release-2101

      - name: Deploy GalaxyKubeMan
        run: >
          (time sh -c "kubectl create ns ${{steps.prefix.outputs.prefix}}; helm install -n ${{steps.prefix.outputs.prefix}} ${{steps.prefix.outputs.prefix}}-gxy-rls edge/galaxykubeman\
              --wait\
              --timeout 2800s\
              --set nfs.storageClass.name=\"nfs-${{steps.prefix.outputs.prefix}}\"\
              --set cvmfs.repositories.cvmfs-gxy-data-${{steps.prefix.outputs.prefix}}=\"data.galaxyproject.org\"\
              --set cvmfs.repositories.cvmfs-gxy-main-${{steps.prefix.outputs.prefix}}=\"main.galaxyproject.org\"\
              --set cvmfs.cache.alienCache.storageClass=\"nfs-${{steps.prefix.outputs.prefix}}\"\
              --set galaxy.persistence.storageClass=\"nfs-${{steps.prefix.outputs.prefix}}\"\
              --set galaxy.cvmfs.data.pvc.storageClassName=cvmfs-gxy-data-${{steps.prefix.outputs.prefix}}\
              --set galaxy.cvmfs.main.pvc.storageClassName=cvmfs-gxy-main-${{steps.prefix.outputs.prefix}}\
              --set galaxy.service.type=LoadBalancer\
              --set galaxy.service.port=8000\
              --set rbac.enabled=false\
              --set galaxy.terra.launch.workspace=\"De novo transcriptome reconstruction with RNA-Seq\"\
              --set galaxy.terra.launch.namespace=\"galaxy-anvil\"\
              --set cvmfs.cache.preload.enabled=false\
              --set galaxy.configs.\"galaxy\.yml\".galaxy.master_api_key=${{secrets.COMMON_PASSWORD}}\
              --set galaxy.configs.\"galaxy\.yml\".galaxy.single_user=\"alex@fake.org\"\
              --set galaxy.configs.\"galaxy\.yml\".galaxy.admin_users=\"alex@fake.org\"\
              --set persistence.nfs.name=\"${{steps.prefix.outputs.prefix}}-nfs-disk\"\
              --set persistence.nfs.persistentVolume.extraSpec.gcePersistentDisk.pdName=\"${{steps.prefix.outputs.prefix}}-nfs-pd\"\
              --set persistence.nfs.size=\"250Gi\"\
              --set persistence.postgres.name=\"${{steps.prefix.outputs.prefix}}-postgres-disk\"\
              --set persistence.postgres.persistentVolume.extraSpec.gcePersistentDisk.pdName=\"${{steps.prefix.outputs.prefix}}-postgres-pd\"\
              --set persistence.postgres.size=\"10Gi\"\
              --set nfs.persistence.existingClaim=\"${{steps.prefix.outputs.prefix}}-nfs-disk-pvc\"\
              --set nfs.persistence.size=\"250Gi\"\
              --set galaxy.postgresql.persistence.existingClaim=\"${{steps.prefix.outputs.prefix}}-postgres-disk-pvc\"\
              --set galaxy.persistence.size=\"200Gi\"\
              --set galaxy.postgresql.galaxyDatabasePassword=${{secrets.COMMON_PASSWORD}}") 1> "$GXY_TMP" 2>> "$GXY_TMP"

      - uses: actions/checkout@master
      - uses: actions/setup-python@v2
        with:
          python-version: '3.x'
      - name: Get Galaxy IP and port
        id: gxyservice
        run: echo "::set-output name=address::$(echo \"http://$(kubectl get svc -n ${{steps.prefix.outputs.prefix}} ${{steps.prefix.outputs.prefix}}-gxy-rls-galaxy -o jsonpath='{.status.loadBalancer.ingress[0].ip}' | sed -e 's/\"//g'):$(kubectl get svc -n ${{steps.prefix.outputs.prefix}} ${{steps.prefix.outputs.prefix}}-gxy-rls-galaxy -o jsonpath='{.spec.ports[0].port}')$(kubectl get ingress -n ${{steps.prefix.outputs.prefix}} ${{steps.prefix.outputs.prefix}}-gxy-rls-galaxy -o jsonpath='{.spec.rules[0].http.paths[0].path}')/\")"
      - name: Create remote single user
        run: curl ${{steps.gxyservice.outputs.address}}
      - name: Install dependencies
        run: python -m pip install planemo ephemeris pysam "galaxy-tool-util>=21.1.0.dev6" bioblend Jinja2 matplotlib
      - name: Create and get API key
        run: echo "::set-output name=key::$(python .github/scripts/create_api_key.py ${{steps.gxyservice.outputs.address}} ${{secrets.COMMON_PASSWORD}})"
        id: api
      - name: Add report from this run
        run: bash ./.github/scripts/report_deployment.sh "$GXY_TMP" anvil-edge-2101 ${{ secrets.GIT_TOKEN }}
  cleanup:
    if: always()
    needs: deploy
    env:
      GKE_ZONE: us-east1-b
    runs-on: ubuntu-latest
    steps:
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@master
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          export_default_credentials: true
      - name: Delete the GKE cluster
        continue-on-error: true
        run: gcloud container clusters delete "${{needs.deploy.outputs.prefix}}" --zone "$GKE_ZONE" --quiet
      - name: Delete the two GCP Disks
        run: gcloud compute disks delete "${{needs.deploy.outputs.prefix}}-postgres-pd" --zone "$GKE_ZONE" --quiet && gcloud compute disks delete "${{needs.deploy.outputs.prefix}}-nfs-pd" --zone "$GKE_ZONE" --quiet
